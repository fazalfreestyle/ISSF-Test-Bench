{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment 3"
      ],
      "metadata": {
        "id": "vIbdVLnWxlVY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QKAYJbVzxkc9",
        "outputId": "c2f6abf1-96fd-4b5c-b18f-17ad73348a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 0.0108 - accuracy: 0.9974\n",
            "Epoch 1: val_loss improved from inf to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 51s 8ms/step - loss: 0.0108 - accuracy: 0.9974 - val_loss: 2.5254e-06 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 1.8693e-04 - accuracy: 1.0000\n",
            "Epoch 2: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 50s 9ms/step - loss: 1.8693e-04 - accuracy: 1.0000 - val_loss: 5.9845e-08 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "5468/5469 [============================>.] - ETA: 0s - loss: 9.9974e-05 - accuracy: 1.0000\n",
            "Epoch 3: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 9.9960e-05 - accuracy: 1.0000 - val_loss: 1.1465e-08 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "5463/5469 [============================>.] - ETA: 0s - loss: 3.5338e-05 - accuracy: 1.0000\n",
            "Epoch 4: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 46s 8ms/step - loss: 3.5302e-05 - accuracy: 1.0000 - val_loss: 1.1686e-09 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "5468/5469 [============================>.] - ETA: 0s - loss: 6.4558e-05 - accuracy: 1.0000\n",
            "Epoch 5: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 45s 8ms/step - loss: 6.4550e-05 - accuracy: 1.0000 - val_loss: 4.5895e-10 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "5468/5469 [============================>.] - ETA: 0s - loss: 4.5178e-05 - accuracy: 1.0000\n",
            "Epoch 6: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 45s 8ms/step - loss: 4.5171e-05 - accuracy: 1.0000 - val_loss: 1.9880e-10 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "5468/5469 [============================>.] - ETA: 0s - loss: 7.8741e-05 - accuracy: 1.0000\n",
            "Epoch 7: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 7.8730e-05 - accuracy: 1.0000 - val_loss: 2.4367e-10 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 5.4159e-05 - accuracy: 1.0000\n",
            "Epoch 8: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 5.4122e-05 - accuracy: 1.0000 - val_loss: 3.0608e-10 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 1.8958e-06 - accuracy: 1.0000\n",
            "Epoch 9: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 1.8945e-06 - accuracy: 1.0000 - val_loss: 1.4866e-11 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 1.2368e-05 - accuracy: 1.0000\n",
            "Epoch 10: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 1.2364e-05 - accuracy: 1.0000 - val_loss: 2.4436e-12 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 2.2626e-05 - accuracy: 1.0000\n",
            "Epoch 11: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.2615e-05 - accuracy: 1.0000 - val_loss: 1.4804e-12 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 6.8818e-06 - accuracy: 1.0000\n",
            "Epoch 12: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 45s 8ms/step - loss: 6.8771e-06 - accuracy: 1.0000 - val_loss: 4.7992e-13 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 9.3752e-07 - accuracy: 1.0000\n",
            "Epoch 13: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 9.3706e-07 - accuracy: 1.0000 - val_loss: 2.3616e-13 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 2.3800e-06 - accuracy: 1.0000\n",
            "Epoch 14: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.3788e-06 - accuracy: 1.0000 - val_loss: 7.9598e-15 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "5468/5469 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "Epoch 15: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 7.3833e-14 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 1.3653e-05 - accuracy: 1.0000\n",
            "Epoch 16: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 1.3653e-05 - accuracy: 1.0000 - val_loss: 1.6411e-14 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 3.9339e-07 - accuracy: 1.0000\n",
            "Epoch 17: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 3.9319e-07 - accuracy: 1.0000 - val_loss: 1.8960e-14 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 2.1523e-07 - accuracy: 1.0000\n",
            "Epoch 18: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.1523e-07 - accuracy: 1.0000 - val_loss: 3.3810e-15 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 1.7013e-06 - accuracy: 1.0000\n",
            "Epoch 19: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 44s 8ms/step - loss: 1.7007e-06 - accuracy: 1.0000 - val_loss: 1.0227e-16 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 4.0110e-06 - accuracy: 1.0000\n",
            "Epoch 20: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 4.0097e-06 - accuracy: 1.0000 - val_loss: 1.0353e-15 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "5463/5469 [============================>.] - ETA: 0s - loss: 1.3688e-07 - accuracy: 1.0000\n",
            "Epoch 21: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 1.3674e-07 - accuracy: 1.0000 - val_loss: 4.6720e-16 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 3.0475e-05 - accuracy: 1.0000\n",
            "Epoch 22: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 3.0465e-05 - accuracy: 1.0000 - val_loss: 1.3756e-16 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 1.6877e-05 - accuracy: 1.0000\n",
            "Epoch 23: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 1.6869e-05 - accuracy: 1.0000 - val_loss: 6.3925e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 8.9764e-09 - accuracy: 1.0000\n",
            "Epoch 24: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 8.9738e-09 - accuracy: 1.0000 - val_loss: 2.9263e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 2.8143e-07 - accuracy: 1.0000\n",
            "Epoch 25: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.8143e-07 - accuracy: 1.0000 - val_loss: 1.3026e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 4.5662e-06 - accuracy: 1.0000\n",
            "Epoch 26: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 4.5639e-06 - accuracy: 1.0000 - val_loss: 3.6025e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 4.1973e-05 - accuracy: 1.0000\n",
            "Epoch 27: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 45s 8ms/step - loss: 4.1973e-05 - accuracy: 1.0000 - val_loss: 3.8401e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 1.6054e-06 - accuracy: 1.0000\n",
            "Epoch 28: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 1.6054e-06 - accuracy: 1.0000 - val_loss: 8.7419e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 2.6708e-06 - accuracy: 1.0000\n",
            "Epoch 29: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.6708e-06 - accuracy: 1.0000 - val_loss: 4.1812e-16 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 5.1343e-07 - accuracy: 1.0000\n",
            "Epoch 30: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 5.1342e-07 - accuracy: 1.0000 - val_loss: 5.6974e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "5464/5469 [============================>.] - ETA: 0s - loss: 1.1427e-06 - accuracy: 1.0000\n",
            "Epoch 31: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 1.1417e-06 - accuracy: 1.0000 - val_loss: 6.3338e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 1.9072e-05 - accuracy: 1.0000\n",
            "Epoch 32: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 42s 8ms/step - loss: 1.9059e-05 - accuracy: 1.0000 - val_loss: 7.1544e-16 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "5468/5469 [============================>.] - ETA: 0s - loss: 2.9060e-05 - accuracy: 1.0000\n",
            "Epoch 33: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.9056e-05 - accuracy: 1.0000 - val_loss: 1.3715e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "5464/5469 [============================>.] - ETA: 0s - loss: 7.5102e-06 - accuracy: 1.0000\n",
            "Epoch 34: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 7.5036e-06 - accuracy: 1.0000 - val_loss: 5.1144e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 2.4458e-08 - accuracy: 1.0000\n",
            "Epoch 35: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.4446e-08 - accuracy: 1.0000 - val_loss: 6.9908e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "5463/5469 [============================>.] - ETA: 0s - loss: 4.9088e-08 - accuracy: 1.0000\n",
            "Epoch 36: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 4.9038e-08 - accuracy: 1.0000 - val_loss: 8.1062e-19 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 1.3303e-05 - accuracy: 1.0000\n",
            "Epoch 37: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 1.3296e-05 - accuracy: 1.0000 - val_loss: 1.2151e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 4.7692e-06 - accuracy: 1.0000\n",
            "Epoch 38: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 4.7659e-06 - accuracy: 1.0000 - val_loss: 1.7567e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "5463/5469 [============================>.] - ETA: 0s - loss: 8.8380e-08 - accuracy: 1.0000\n",
            "Epoch 39: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 8.8287e-08 - accuracy: 1.0000 - val_loss: 9.4146e-16 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 2.8466e-05 - accuracy: 1.0000\n",
            "Epoch 40: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 45s 8ms/step - loss: 2.8446e-05 - accuracy: 1.0000 - val_loss: 1.7727e-16 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "5469/5469 [==============================] - ETA: 0s - loss: 2.9695e-07 - accuracy: 1.0000\n",
            "Epoch 41: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.9695e-07 - accuracy: 1.0000 - val_loss: 4.0807e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 2.1830e-08 - accuracy: 1.0000\n",
            "Epoch 42: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 2.1823e-08 - accuracy: 1.0000 - val_loss: 1.4546e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 3.1954e-07 - accuracy: 1.0000\n",
            "Epoch 43: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 3.1938e-07 - accuracy: 1.0000 - val_loss: 3.7877e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 8.2663e-09 - accuracy: 1.0000\n",
            "Epoch 44: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 8.2621e-09 - accuracy: 1.0000 - val_loss: 2.0354e-19 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 4.4704e-09 - accuracy: 1.0000\n",
            "Epoch 45: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 44s 8ms/step - loss: 4.4674e-09 - accuracy: 1.0000 - val_loss: 8.9596e-21 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 1.0522e-09 - accuracy: 1.0000\n",
            "Epoch 46: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 44s 8ms/step - loss: 1.0515e-09 - accuracy: 1.0000 - val_loss: 2.8386e-20 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 47/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 1.1237e-05 - accuracy: 1.0000\n",
            "Epoch 47: val_loss improved from 0.00000 to 0.00000, saving model to ANN_best_model_Analomaly.keras\n",
            "5469/5469 [==============================] - 44s 8ms/step - loss: 1.1234e-05 - accuracy: 1.0000 - val_loss: 5.4465e-22 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 48/100\n",
            "5463/5469 [============================>.] - ETA: 0s - loss: 2.9169e-05 - accuracy: 1.0000\n",
            "Epoch 48: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 47s 9ms/step - loss: 2.9139e-05 - accuracy: 1.0000 - val_loss: 1.0962e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 49/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 5.8223e-07 - accuracy: 1.0000\n",
            "Epoch 49: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 44s 8ms/step - loss: 5.8205e-07 - accuracy: 1.0000 - val_loss: 2.9277e-20 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 50/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 4.1487e-05 - accuracy: 1.0000\n",
            "Epoch 50: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 46s 8ms/step - loss: 4.1466e-05 - accuracy: 1.0000 - val_loss: 1.4294e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 51/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 1.0921e-05 - accuracy: 1.0000\n",
            "Epoch 51: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 46s 8ms/step - loss: 1.0914e-05 - accuracy: 1.0000 - val_loss: 7.7832e-19 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 52/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 1.5916e-05 - accuracy: 1.0000\n",
            "Epoch 52: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 45s 8ms/step - loss: 1.5908e-05 - accuracy: 1.0000 - val_loss: 1.9291e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 53/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 7.2517e-05 - accuracy: 1.0000\n",
            "Epoch 53: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 48s 9ms/step - loss: 7.2480e-05 - accuracy: 1.0000 - val_loss: 6.7744e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 54/100\n",
            "5467/5469 [============================>.] - ETA: 0s - loss: 5.8406e-07 - accuracy: 1.0000\n",
            "Epoch 54: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 44s 8ms/step - loss: 5.8387e-07 - accuracy: 1.0000 - val_loss: 5.3441e-19 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 55/100\n",
            "5466/5469 [============================>.] - ETA: 0s - loss: 9.0642e-06 - accuracy: 1.0000\n",
            "Epoch 55: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 44s 8ms/step - loss: 9.0596e-06 - accuracy: 1.0000 - val_loss: 6.7473e-18 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 56/100\n",
            "5465/5469 [============================>.] - ETA: 0s - loss: 3.5935e-06 - accuracy: 1.0000\n",
            "Epoch 56: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 43s 8ms/step - loss: 3.5910e-06 - accuracy: 1.0000 - val_loss: 2.3679e-20 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 57/100\n",
            "5464/5469 [============================>.] - ETA: 0s - loss: 3.5376e-05 - accuracy: 1.0000\n",
            "Epoch 57: val_loss did not improve from 0.00000\n",
            "5469/5469 [==============================] - 44s 8ms/step - loss: 3.5346e-05 - accuracy: 1.0000 - val_loss: 5.3298e-17 - val_accuracy: 1.0000 - lr: 0.0010\n",
            "Epoch 57: early stopping\n",
            "4688/4688 [==============================] - 13s 3ms/step - loss: 5.3048e-17 - accuracy: 1.0000\n",
            "4688/4688 [==============================] - 10s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANN Results:\n",
            "Loss: 5.304796949447497e-17\n",
            "Accuracy: 1.0\n",
            "F1 Score: 1.0\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 14717      0]\n",
            " [     0 135283]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00     14717\n",
            "         1.0       1.00      1.00      1.00    135283\n",
            "\n",
            "    accuracy                           1.00    150000\n",
            "   macro avg       1.00      1.00      1.00    150000\n",
            "weighted avg       1.00      1.00      1.00    150000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "# Load and prepare data\n",
        "ECU1 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU1.csv\", header=None))\n",
        "ECU2 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU2.csv\", header=None))\n",
        "ECU3 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU3.csv\", header=None))\n",
        "ECU4 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU4.csv\", header=None))\n",
        "ECU5 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU5.csv\", header=None))\n",
        "ECU6 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU6.csv\", header=None))\n",
        "ECU7 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU7.csv\", header=None))\n",
        "ECU8 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU8.csv\", header=None))\n",
        "ECU9 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU9.csv\", header=None))\n",
        "ECU10 = np.array(pd.read_csv(\"/content/drive/MyDrive/TestBench Dataset/ECU10.csv\", header=None))\n",
        "\n",
        "X = np.concatenate((ECU1[:, :-1], ECU2[:, :-1], ECU3[:, :-1], ECU4[:, :-1], ECU5[:, :-1], ECU6[:, :-1], ECU7[:, :-1], ECU8[:, :-1], ECU9[:, :-1], ECU10[:, :-1]))\n",
        "y = np.concatenate((np.zeros(ECU1.shape[0]), np.ones(ECU2.shape[0]), np.ones(ECU3.shape[0]), np.ones(ECU4.shape[0]), np.ones(ECU5.shape[0]), np.ones(ECU6.shape[0]), np.ones(ECU7.shape[0]), np.ones(ECU8.shape[0]), np.ones(ECU9.shape[0]), np.ones(ECU10.shape[0])))\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Normalize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Function to plot training history\n",
        "def plot_history(history, model_name):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title(f'{model_name} Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "# ANN Model\n",
        "def build_ann():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(256, input_dim=X_train.shape[1], activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train and evaluate ANN model\n",
        "def train_evaluate_ann():\n",
        "    ann_model = build_ann()\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
        "    model_checkpoint = ModelCheckpoint('ANN_best_model_Analomaly.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, verbose=1)\n",
        "\n",
        "    history = ann_model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                            epochs=100, batch_size=128, callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
        "\n",
        "    loss, accuracy = ann_model.evaluate(X_test, y_test)\n",
        "    y_pred_prob = ann_model.predict(X_test)\n",
        "    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    plot_history(history, 'ANN')\n",
        "\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "    class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "    return {'model': 'ANN', 'loss': loss, 'accuracy': accuracy, 'f1_score': f1, 'conf_matrix': conf_matrix, 'class_report': class_report}\n",
        "\n",
        "# Train and evaluate the ANN model\n",
        "ann_results = train_evaluate_ann()\n",
        "\n",
        "# Print results\n",
        "print(\"ANN Results:\")\n",
        "print(f\"Loss: {ann_results['loss']}\")\n",
        "print(f\"Accuracy: {ann_results['accuracy']}\")\n",
        "print(f\"F1 Score: {ann_results['f1_score']}\")\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(ann_results['conf_matrix'])\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(ann_results['class_report'])\n"
      ]
    }
  ]
}